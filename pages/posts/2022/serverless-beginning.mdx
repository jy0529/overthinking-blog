import Post from '../../../components/layouts/post'

export default function children({ children }) {
    return <Post
        title='Serverless 初学者扫盲'
        keywords="Serverless | Serverless初学者 | Serverless 核心概念"
        description=''
    >{children}</Post>
}

# Serverless 初学者之扫盲篇

## 诞生之初
    <img src="/serverless-background.png" />

如上图所示, Serverless 的发展大致可以分为四个阶段:

1) **Bare-mental**

      这是一个物理机的时代，想要搭建一个网站，你先要购买一台服务器，安装好路由器、交换机，构建好网络环境，安装服务器软件，数据库等
    最重要的是要维持好物理机的正常运行，不能突然断电，还要维护好硬盘、内存等，可以看出这是非常耗时耗力气的工作，当然你的服务器可以找 IDC 托管, 但这样会很贵。
      
2) **Virtual Machine**

      既然物理上的机器和硬件维护如此之麻烦，能否有专人服务使得我们只需要告诉他们要什么类型的 CPU、多大的内存、多大的磁盘等等呢?

      由于虚拟化技术的发展，我们可以将物理上的硬件资源抽象为云上的计算资源，于是，客户只需要到云厂商里选购计算资源即可，比如要购买一台 4G 8核的服务器，
      10M带宽，剩下的服务器选购、维护工作就交由云厂商了，AWS 的 EC2 、阿里云的 ECS 、腾讯云的 CVM 等就是这一类的产品。

3) **Container**

      虽然我们不用维护物理机已经进了一大步了，但离我们搭建一个 Web 服务器还有一段距离，包括但不限于操作系统的安装、服务器软件的安装、数据库软件的安装和配置等等。

      由于容器化的发展，我们可以在虚拟机上搭建出很多个容器，它们之间是相互隔离的，容器内部可以运行安装好的程序，利用这个特点，我们只需要关注容器里需要什么依赖，它就自动帮我们构建好，
      并且很容易动态扩缩容，更好地应对突发流量的场景。最典型的技术有 Docker、K8s 等。
      

4) **Serverless**

      虽然我们只关注容器即可，但仍必不可少的要学习如 Docker、K8s 之类的容器配置、运维知识才能构建出我们的应用。

      这就引发出一个思考：从物理机的一个大部件 -> 虚拟化的计算资源(OS、虚拟磁盘等) -> 容器的配置和运维， 关注点都是**我们的应用在哪里部署和运行？**
      而我们希望的答案是知道的越少越好、越简单操作越好。于是，我们可以大胆猜测：能否我们只关注改动业务代码，而应用的部署和运维就交由云厂商去做呢？

      这其实就是 Serverless 解决的问题，从物理机到操作系统到容器进程，我们需要关注的越来越小，那最小的可执行程序是什么呢？**其实是一个函数**。


      Serverless 中最核心的就是函数即服务，代表性产品有 AWS Lamda，我们只需要在函数里编写业务代码，再定义这个函数的触发器即可，当并发数过多会自动扩容，当并发数变少则会自动缩容，
      按调用次数和内存使用率计费，构造出一个按需使用计费的模式。


## Trade-off
    ### pros
        1) 按需使用计费模式
        2) 自动扩缩容
        3) 专注于业务逻辑本身

    ### cons
        1) 有一定的冷启动时间延迟
        2) 监控和调试变得困难
        3) 第三方云厂商锁定(无法自由使用)

    ### 适用场景
        1) 通过 HTTP 触发的服务而非 RPC
        2) 无状态的服务而非依赖共享内存的服务
        3) 不适合对性能要求极高的服务

## 价值
    ### 趋势
        Serverless 是一种开放新范式，其推崇的是计算资源的按需使用、可持续发展，目的是尽最大可能压缩成本和让研发人员更专注业务逻辑，这是非常适合新项目落地、
        旧项目逐步改造成 Serverless 服务，用得越多越省钱。同时，开发思维也要转变成适应 Serverless 服务的特点，对研发的要求更高了。

    ### 分工
        从前端做UI然后把页面交给后端贴合 -> 后端接口化 + 前端UI交互 -> 前端UI交互和BFF + 后端接口服务
        
        可以看出，研发之间的分工越来越明确，其共同目标都是为了提高研发速率和保证质量

        举个例子,以前的前后端分离各自开发都很爽但一结合起来就出各种问题(字段数据结构不匹配，缺失，接口调用不合理等)

        作为页面展示所需的数据应该由前端负责，自主地定义数据结构和获取，于是出现了 BFF 的胶水层，用来适配和粘合后台的接口服务

        而 BFF 服务也是要部署的，前端一般采用 Node.js，面对越来越多的 BFF 服务，就需要对其进行管理，这就涉及服务的部署和运维了，前端关注的非业务知识变多

        所以，现在 BFF 的模式也朝着 SFF (Serverless For Frontend)，将服务托管在 Serverless 平台上，则无需关注其部署和运维了，减少认知和节省时间。

        横向的分工大抵如此，或许我们可以探索纵向分工，每个研发单独为一个业务功能负责(从前端到后台服务), 减少不必要的沟通，更清楚功能的实现全貌，从而提高速度和稳定性，
        但这要求研发人员的素质更高了，幸运的是，现在后台服务和部署越来越标准化，大多数业务可以调用云厂商的服务来做底层实现。

    ### 财务
        1) 按需计费模式使得很多长尾流量的应用在调用次数少的时候节省成本，运维费用下降
        2) 操作成本降低，更专注于业务，对于以往专门做服务运维的人员可能会减少，招懂 Serverless 服务的研发, 降低人力成本

## 参考资料
    1. [The Origins of Serverless](https://dashbird.io/blog/origin-of-serverless/)
    2. [What is Serverless?](https://www.ibm.com/cloud/learn/serverless?mhsrc=ibmsearch_a&mhq=Serverless#toc-what-is-se-K3xZyJmF)